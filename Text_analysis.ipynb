{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d80212-076b-49b5-8244-63c11e1d0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def tag_visible(element):    \n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]', 'a', 'span', 'ul', 'ol', 'p[tdm-descr]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    if element.parent.name in ['p', 'h1']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def text_from_html(body):\n",
    "    soup = BeautifulSoup(body)\n",
    "    texts = soup.article.findAll(string=True)\n",
    "    visible_texts = filter(tag_visible, texts)  \n",
    "    return u\" \".join(t.strip() for t in visible_texts)\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\"}\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Input.xlsx\")\n",
    "for i in range(len(df)):\n",
    "    text_file_name = str(int(df['URL_ID'][i]))\n",
    "\n",
    "    URL = df['URL'][i]\n",
    "    # print(URL)\n",
    "    response = requests.get(URL,headers=headers, cookies={'cookies':''})\n",
    "    article_text = text_from_html(response.text)\n",
    "    # print(article_text)\n",
    "\n",
    "    ### creating text file with URL_ID as name containing title and text from the article on the URL ### \n",
    "    with open(r'C:\\Users\\madaa\\Downloads\\New folder\\data extracted'+text_file_name+\".txt\", 'w', encoding=\"utf-8\") as file: \n",
    "        file.write(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33c5e46-44ee-4f32-8c1d-4f719f5d170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99de5c1e-ff2e-4453-9cec-46aec7d5a13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto fill\n",
    "def auto_fill(link):\n",
    "    from bs4 import BeautifulSoup\n",
    "    from bs4.element import Comment\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    def tag_visible(element):\n",
    "        if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]',\"#menu-main-6\"]:\n",
    "            return False\n",
    "        if isinstance(element, Comment):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def text_from_html(body):\n",
    "        soup = BeautifulSoup(body)\n",
    "        texts = soup.findAll(text=True)\n",
    "        visible_texts = filter(tag_visible, texts)  \n",
    "        return u\" \".join(t.strip() for t in visible_texts)\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\"}\n",
    "    \n",
    "    \n",
    "    response = requests.get(link, headers=headers, cookies={'cookies':''})\n",
    "    \n",
    "    \n",
    "    blog=text_from_html(response.text)\n",
    "    \n",
    "    blog=blog.split()\n",
    "    \n",
    "    # blog=list(map(lambda x:x.lower(),blog))\n",
    "    # print(blog)\n",
    "    \n",
    "    blog = [word.lower() for word in blog]\n",
    "    # print(blog)\n",
    "    \n",
    "    pos=open(r\"C:\\Users\\madaa\\Downloads\\MasterDictionary-20250107T085954Z-001\\MasterDictionary\\positive-words.txt\",'r')\n",
    "    postive_words=pos.read()\n",
    "    # print(postive_words)\n",
    "    \n",
    "    \n",
    "    postive_words=postive_words.split()\n",
    "    \n",
    "    # postive_words=list(map(lambda x:x.lower(),postive_words))\n",
    "    # print(postive_words)\n",
    "    \n",
    "    pos.close()\n",
    "    \n",
    "    p=0\n",
    "    for x in blog:\n",
    "        if x in postive_words:\n",
    "            p+=1\n",
    "    # print(p)      \n",
    "    \n",
    "    # df=pd.read_excel(r\"C:\\Users\\gagan\\text analytics\\Output Data Structure.xlsx\")\n",
    "    # df.loc[0,\"POSITIVE SCORE\"]=p\n",
    "    # # print(df)\n",
    "    # df.to_excel(r\"C:\\Users\\gagan\\text analytics\\Output Data Structure.xlsx\")\n",
    "    \n",
    "    \n",
    "    # positive score\n",
    "    pos=open(r\"C:\\Users\\madaa\\Downloads\\MasterDictionary-20250107T085954Z-001\\MasterDictionary\\positive-words.txt\",'r')\n",
    "    postive_words=pos.read()\n",
    "    # print(postive_words)\n",
    "    \n",
    "    \n",
    "    postive_words=postive_words.split(\"\\n\")\n",
    "    # print(postive_words)\n",
    "    \n",
    "    pos.close()\n",
    "    \n",
    "    P=0\n",
    "    for x in blog:\n",
    "        if x in postive_words:\n",
    "            P+=1\n",
    "    print(P)   \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"POSITIVE SCORE\"]=P\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    #negative score\n",
    "    neg=open(r\"C:\\Users\\madaa\\Downloads\\MasterDictionary-20250107T085954Z-001\\MasterDictionary\\negative-words.txt\",'r')\n",
    "    negative_words=neg.read()\n",
    "    # print(negative_words)\n",
    "    \n",
    "    \n",
    "    negative_words=negative_words.split(\"\\n\")\n",
    "    negative_words = [word.lower() for word in negative_words]\n",
    "    # print(negative_words)\n",
    "    pos.close()\n",
    "    \n",
    "    \n",
    "    N=0\n",
    "    for x in blog:\n",
    "        if x in negative_words:\n",
    "            N+=1\n",
    "    print(N)   \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"NEGATIVE SCORE\"]=N\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Polarity Score\n",
    "    polarity_score = (P - N) / ((P + N) + 0.000001)\n",
    "    print(polarity_score)\n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"POLARITY SCORE\"]=polarity_score\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Subjectivity Score\n",
    "    stop1=open(r\"C:\\Users\\madaa\\Downloads\\StopWords-20250107T090001Z-001\\StopWords\\StopWords_Auditor.txt\",'r')\n",
    "    stop1=stop1.read()\n",
    "    stop1=stop1.split()\n",
    "    stop1 = [word.lower() for word in stop1]\n",
    "    # print(stop1)\n",
    "    l1=[]\n",
    "    for s in blog:\n",
    "        if s not in stop1:\n",
    "            l1.append(s)\n",
    "    # print(l1)\n",
    "    print(len(l1))\n",
    "    \n",
    "    \n",
    "    l1\n",
    "    stop2=open(r\"C:\\Users\\madaa\\Downloads\\StopWords-20250107T090001Z-001\\StopWords\\StopWords_Currencies.txt\",'r')\n",
    "    stop2=stop2.read()\n",
    "    stop2=stop2.split()\n",
    "    stop2 = [word.lower() for word in stop2]\n",
    "    # print(stop2)\n",
    "    \n",
    "    l2=[]\n",
    "    for c in l1:\n",
    "        if c not in stop2:\n",
    "            l2.append(c)\n",
    "    # print(l2)\n",
    "    print(len(l2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    stop3=open(r\"C:\\Users\\madaa\\Downloads\\StopWords-20250107T090001Z-001\\StopWords\\StopWords_DatesandNumbers.txt\",'r')\n",
    "    stop3=stop3.read()\n",
    "    stop3=stop3.split()\n",
    "    stop3 = [word.lower() for word in stop3]\n",
    "    # print(stop3)\n",
    "    l3=[]\n",
    "    for d in l2:\n",
    "        if d not in stop3:\n",
    "            l3.append(d)\n",
    "    # print(l3)\n",
    "    print(len(l3))\n",
    "    \n",
    "    \n",
    "    \n",
    "    stop4=open(r\"C:\\Users\\madaa\\Downloads\\StopWords-20250107T090001Z-001\\StopWords\\StopWords_Generic.txt\",'r')\n",
    "    stop4=stop4.read()\n",
    "    stop4=stop4.split()\n",
    "    stop4 = [word.lower() for word in stop4]\n",
    "    # print(stop4)\n",
    "    l4=[]\n",
    "    for d in l3:\n",
    "        if d not in stop4:\n",
    "            l4.append(d)\n",
    "    # print(l4)\n",
    "    print(len(l4))\n",
    "    \n",
    "    \n",
    "    \n",
    "    l4\n",
    "    stop5=open(r\"C:\\Users\\madaa\\Downloads\\StopWords-20250107T090001Z-001\\StopWords\\StopWords_GenericLong.txt\",'r')\n",
    "    stop5=stop5.read()\n",
    "    stop5=stop5.split()\n",
    "    stop5 = [word.lower() for word in stop5]\n",
    "    # print(stop5)\n",
    "    l5=[]\n",
    "    for d in l4:\n",
    "        if d not in stop5:\n",
    "            l5.append(d)\n",
    "    # print(l5)\n",
    "    print(len(l5))\n",
    "    \n",
    "    l5\n",
    "    stop6=open(r\"C:\\Users\\madaa\\Downloads\\StopWords-20250107T090001Z-001\\StopWords\\StopWords_Geographic.txt\",'r')\n",
    "    stop6=stop6.read()\n",
    "    stop6=stop6.split()\n",
    "    stop6 = [word.lower() for word in stop6]\n",
    "    # print(stop6)\n",
    "    \n",
    "    l6=[]\n",
    "    for d in l5:\n",
    "        if d not in stop6:\n",
    "            l6.append(d)\n",
    "    # print(l6)\n",
    "    print(len(l6))\n",
    "    l6\n",
    "    stop7=open(r\"C:\\Users\\madaa\\Downloads\\StopWords-20250107T090001Z-001\\StopWords\\StopWords_Names.txt\",'r')\n",
    "    stop7=stop7.read()\n",
    "    stop7=stop7.split()\n",
    "    stop7 = [word.lower() for word in stop7]\n",
    "    # print(stop7)\n",
    "    l7=[]\n",
    "    for d in l6:\n",
    "        if d  not in stop7:\n",
    "            l7.append(d)\n",
    "    # print(l7)\n",
    "    print(len(l7))\n",
    "    total_words_after_cleaning=len(l7)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Subjectivity Score\n",
    "    Subjectivity_Score = (P + N)/ ((total_words_after_cleaning) + 0.000001)\n",
    "    print(Subjectivity_Score)\n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"SUBJECTIVITY SCORE\"]=Subjectivity_Score\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False) \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Average Sentence Length \n",
    "    from bs4 import BeautifulSoup\n",
    "    from bs4.element import Comment\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    \n",
    "    def tag_visible(element):\n",
    "        if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]',\"#menu-main-6\"]:\n",
    "            return False\n",
    "        if isinstance(element, Comment):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def text_from_html(body):\n",
    "        soup = BeautifulSoup(body)\n",
    "        texts = soup.findAll(text=True)\n",
    "        visible_texts = filter(tag_visible, texts)  \n",
    "        return u\" \".join(t.strip() for t in visible_texts)\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\"}\n",
    "    \n",
    "    \n",
    "    response = requests.get('https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-3-2/',\n",
    "                            headers=headers, cookies={'cookies':''})\n",
    "    \n",
    "    \n",
    "    word1=text_from_html(response.text)\n",
    "    word=word1.split( )\n",
    "    # print(word)\n",
    "    the_number_of_words=len(word)\n",
    "    \n",
    "    print(the_number_of_words)\n",
    "    \n",
    "    sentence=word1.split(\".\")\n",
    "    # print(sentence)\n",
    "    sentence_length=len(sentence)\n",
    "    print(sentence_length)\n",
    "    \n",
    "    # average sentence lenght\n",
    "    Average_Sentence_Length = the_number_of_words / sentence_length\n",
    "    print(Average_Sentence_Length)\n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"AVG SENTENCE LENGTH\"]=Average_Sentence_Length\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    # complex words\n",
    "    word=word1.split( )\n",
    "    def count_syllables(r):\n",
    "        vowels = \"aeiouAEIOU\"\n",
    "        count = 0\n",
    "        \n",
    "        for i in range(len(r)):\n",
    "            if r[i] in vowels:\n",
    "                # To avoid counting consecutive vowels as multiple syllables\n",
    "                if i == 0 or r[i-1] not in vowels:\n",
    "                    count += 1\n",
    "        \n",
    "        return count\n",
    "    \n",
    "    def is_complex(r):\n",
    "        syllable_count = count_syllables(r)\n",
    "        if syllable_count == 2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    # Input from the user\n",
    "    # word = input(\"Enter a word: \")\n",
    "    \n",
    "    # # Determine if the word is complex\n",
    "    # if is_complex(word):\n",
    "    #     print(f\"The word '{word}' is complex.\")\n",
    "    # else:\n",
    "    #     print(f\"The word '{word}' is not complex.\")\n",
    "    \n",
    "    c=0\n",
    "    for r in word:\n",
    "        if is_complex(r):\n",
    "            c=c+1\n",
    "    complex_words=c\n",
    "    print(complex_words)\n",
    "    \n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"COMPLEX WORD COUNT\"]=complex_words\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    # Percentage of Complex words = the number of complex words / the number of words \n",
    "    \n",
    "    print(\"the_number_of_words: \", the_number_of_words)\n",
    "    print(\"complex_words: \", complex_words)\n",
    "    \n",
    "    Percentage_of_Complex_words=(complex_words/the_number_of_words)*100\n",
    "    print(\"percentage of complex word: \", Percentage_of_Complex_words)\n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"PERCENTAGE OF COMPLEX WORDS\"]=Percentage_of_Complex_words\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "    print(\"Average_Sentence_Length:\",Average_Sentence_Length)\n",
    "    print(\"percentage of complex word: \", Percentage_of_Complex_words)\n",
    "    # Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "    fog_index=0.4 * (Average_Sentence_Length + Percentage_of_Complex_words)\n",
    "    print(\"Fog Index :\",fog_index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"FOG INDEX\"]=fog_index\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    print(\"the_number_of_words: \", the_number_of_words)\n",
    "    print(\"sentence_length:\", sentence_length)\n",
    "    Average_Number_of_Words_Per_Sentence = the_number_of_words / sentence_length\n",
    "    print(\"Average_Number_of_Words_Per_Sentence:\", Average_Number_of_Words_Per_Sentence)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"AVG NUMBER OF WORDS PER SENTENCE\"]=Average_Number_of_Words_Per_Sentence\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # word_count\n",
    "    \n",
    "    l7\n",
    "    # print(len(l7))\n",
    "    s=\" \".join(l7)\n",
    "    text=s\n",
    "    # print(text)\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "     \n",
    "    for i in text:\n",
    "        if i in punc:\n",
    "            text = text.replace(i, \"\")\n",
    "     \n",
    "    \n",
    "    # print( text)\n",
    "    word_count=text.split()\n",
    "    # print(word_count)\n",
    "    word_count=len(word_count)\n",
    "    print(\"word count:\",word_count)\n",
    "    \n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"WORD COUNT\"]=word_count\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # personal pronouns\n",
    "    word_count=text.split()\n",
    "    p=[\"I\",\"We\",\"My\",\"Our\",\"Us\"]\n",
    "    \n",
    "    pro=[word.lower() for word in p]\n",
    "    # print(pro)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(word_count)\n",
    "    \n",
    "    count=0\n",
    "    for d in word_count:\n",
    "        if d in pro:\n",
    "            count=count+1\n",
    "    print(\"Count of Personal Pronoun:\",count)\n",
    "    \n",
    "            \n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"PERSONAL PRONOUNS\"]=count\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(blog)\n",
    "    l=0\n",
    "    for i in blog:\n",
    "        l=l+len(i)\n",
    "    Sum_character=l\n",
    "    print(\"Sum_character:\",Sum_character)\n",
    "    print(\"the_number_of_words: \", the_number_of_words)\n",
    "    average_word_length=Sum_character/the_number_of_words\n",
    "    print(\"average_word_length:\",average_word_length)\n",
    "    \n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"AVG WORD LENGTH\"]=average_word_length\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "    \n",
    "    # syllabe per word\n",
    "    blog\n",
    "    \n",
    "    count=0\n",
    "    s='My vowel ios zoo'\n",
    "    s=s.split()\n",
    "    s=blog\n",
    "    for word in s:\n",
    "         for i in range(len(word)):\n",
    "            if i==len(word)-1 and word[i] in 'aeiou':\n",
    "                count+=1\n",
    "        \n",
    "            elif word[i] in 'aeiou' and word[i+1] not in 'aeiou':\n",
    "                count+=1\n",
    "    print(count)Z\n",
    "    \n",
    "    df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "    df.loc[h,\"SYLLABLE PER WORD\"]=count\n",
    "    # print(df)\n",
    "    df.to_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\",index=False)\n",
    "    \n",
    "import pandas as pd\n",
    "h=0\n",
    "df=pd.read_excel(r\"C:\\Users\\madaa\\Downloads\\New folder\\Output Data Structure.xlsx\")\n",
    "for link in df[\"URL\"]:\n",
    "    print(auto_fill(link))\n",
    "    h=h+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b364f38e-4faa-4a22-84cb-27a1700bc8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
